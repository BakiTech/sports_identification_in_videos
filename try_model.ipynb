{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 512\n",
    "\n",
    "class_vocab = ['body-building', 'boxing', 'calesthenics', 'cycling', 'swimming', 'yoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sequence_model = load_model( 'models\\model_83.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)       [(None, 20, 512)]            0         []                            \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)              (None, 20, 128)              328192    ['input_27[0][0]',            \n",
      "                                                                     'input_28[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)              (None, 20, 32)               20608     ['lstm_22[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)        (None, 640)                  0         ['lstm_23[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, 640)                  2560      ['flatten_11[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 640)                  0         ['batch_normalization_105[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 8)                    5128      ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 6)                    54        ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 356542 (1.36 MB)\n",
      "Trainable params: 355262 (1.36 MB)\n",
      "Non-trainable params: 1280 (5.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3, VGG16\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "def build_feature_extractor(model_name=\"inception_v3\"):\n",
    "    if model_name == \"inception_v3\":\n",
    "        feature_extractor = InceptionV3(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            pooling=\"avg\",\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        )\n",
    "        preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    elif model_name == \"vgg16\":\n",
    "        feature_extractor = VGG16(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            pooling=\"avg\",\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        )\n",
    "        preprocess_input = keras.applications.vgg16.preprocess_input\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Supported names: 'inception_v3', 'vgg16'\")\n",
    "\n",
    "    inputs = Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return Model(inputs, outputs, name=f\"{model_name}_feature_extractor\")\n",
    "\n",
    "# To use InceptionV3\n",
    "inception_feature_extractor = build_feature_extractor(model_name=\"inception_v3\")\n",
    "\n",
    "# To use VGG16\n",
    "vgg16_feature_extractor = build_feature_extractor(model_name=\"vgg16\")\n",
    "\n",
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = vgg16_feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "import os\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body-building', 'boxing', 'calesthenics', 'cycling', 'swimming', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = ''\n",
    "dataset_path = os.listdir( path)\n",
    "\n",
    "label_types = os.listdir( path)\n",
    "print (label_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tag                                         video_name\n",
      "0  body-building  C:/Users/aminb/Downloads/RNN/sports_dataset/bo...\n",
      "1  body-building  C:/Users/aminb/Downloads/RNN/sports_dataset/bo...\n",
      "2  body-building  C:/Users/aminb/Downloads/RNN/sports_dataset/bo...\n",
      "3  body-building  C:/Users/aminb/Downloads/RNN/sports_dataset/bo...\n",
      "4  body-building  C:/Users/aminb/Downloads/RNN/sports_dataset/bo...\n",
      "       tag                                         video_name\n",
      "1633  yoga  C:/Users/aminb/Downloads/RNN/sports_dataset/yo...\n",
      "1634  yoga  C:/Users/aminb/Downloads/RNN/sports_dataset/yo...\n",
      "1635  yoga  C:/Users/aminb/Downloads/RNN/sports_dataset/yo...\n",
      "1636  yoga  C:/Users/aminb/Downloads/RNN/sports_dataset/yo...\n",
      "1637  yoga  C:/Users/aminb/Downloads/RNN/sports_dataset/yo...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir( path + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str( path + '/' +item) + '/' + room))\n",
    "\n",
    "# Build a dataframe\n",
    "data = pd.DataFrame( data=rooms, columns=['tag', 'video_name'])\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: C:/Users/aminb/Downloads/RNN/sports_dataset/swimming/Front View Caucasian Male Swimmer Swimming Stock Footage Video (100% Royalty-free) 1046518693.webm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "  swimming: 98.37%\n",
      "  yoga:  1.48%\n",
      "  cycling:  0.15%\n",
      "  boxing:  0.00%\n",
      "  calesthenics:  0.00%\n",
      "  body-building:  0.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_video = np.random.choice( data[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction( test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt='test' width='520' height='440' controls><source src='C:/Users/aminb/Downloads/RNN/sports_dataset/swimming/Front View Caucasian Male Swimmer Swimming Stock Footage Video (100% Royalty-free) 1046518693.webm' type='video/mp4' style='height:300px;width:300px'></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "html = \"<video alt='test' width='520' height='440' controls><source src='\" + test_video + \"' type='video/mp4' style='height:300px;width:300px'></video>\"\n",
    "\n",
    "HTML( html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
